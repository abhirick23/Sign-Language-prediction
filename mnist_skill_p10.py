# -*- coding: utf-8 -*-
"""MNIST_skill p10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QxltNn0ltEP4pA7hN2bzcmS-zPQksXZb
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/gdrive/')
# %cd /gdrive

ls

cd/gdrive/My Drive/MNIST/Sign_MNIST/

ls

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from tensorflow.keras import models, layers
from tensorflow.keras.utils import to_categorical

train = pd.read_csv('sign_mnist_train.csv')
test = pd.read_csv('sign_mnist_test.csv')

train.head()

labels = train['label']

train.drop('label', axis = 1, inplace = True)
print(train.shape)

x_train = train.values.reshape(train.shape[0],28,28,1)
plt.imshow(x_train[0].reshape(28,28), cmap='gray')

plt.figure(figsize = (18,8))
sns.countplot(x =labels)

labels = to_categorical(labels)
print(labels.shape)

x_train, x_test, y_train, y_test = train_test_split(x_train, labels, test_size = 0.2, random_state = 2)
x_train = x_train / 255.0
x_test = x_test / 255.0
print(x_train.shape)
print(x_test.shape)

num_classes = 25
input_shape = (28,28,1)

model = models.Sequential()
model.add(layers.Conv2D(64, kernel_size=(3,3), padding='same', activation = 'relu', input_shape=input_shape ))
model.add(layers.MaxPooling2D(pool_size = (2, 2)))
model.add(layers.Conv2D(64, kernel_size = (3, 3), padding='same', activation = 'relu'))
model.add(layers.MaxPooling2D(pool_size = (2, 2)))
model.add(layers.Conv2D(64, kernel_size = (3, 3), padding='same', activation = 'relu'))
model.add(layers.MaxPooling2D(pool_size = (2, 2)))
model.add(layers.Flatten())
model.add(layers.Dense(128, activation = 'relu'))
model.add(layers.Dropout(0.20))
model.add(layers.Dense(num_classes, activation = 'softmax'))
model.summary()

model.compile(loss = 'categorical_crossentropy', optimizer = 'adam' , metrics = ['accuracy'])

batch_size = 128
num_epochs = 5
history = model.fit(x_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_data = (x_test, y_test))

keys=history.history.keys()
print(keys)
def show_train_history(hisData,t1,t2): 
    plt.plot(hisData.history[t1])
    plt.plot(hisData.history[t2])
    plt.title('Training History')
    plt.ylabel('value')
    plt.xlabel('epoch')
    plt.legend([t1, t2], loc='upper left')
    plt.show()
show_train_history(history, 'loss', 'val_loss')
show_train_history(history, 'accuracy', 'val_accuracy')

score = model.evaluate(x_test, y_test, verbose = 0)
print('Test loss: ', score[0])
print('Test accuracy: ', score[1])